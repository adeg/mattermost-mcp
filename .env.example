# Mattermost MCP Server Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# Required - Mattermost Connection
# =============================================================================

# Mattermost server URL (without /api/v4)
MATTERMOST_URL=https://mattermost.example.com

# Personal access token for authentication
MATTERMOST_TOKEN=your-token-here

# Team ID to operate on
MATTERMOST_TEAM_ID=your-team-id-here

# =============================================================================
# Optional - Server Configuration
# =============================================================================

# HTTP port for the server (default: 8000)
HTTP_PORT=8000

# Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)
LOG_LEVEL=INFO

# Log format: json or console (default: json)
LOG_FORMAT=json

# =============================================================================
# Optional - Topic Monitoring
# =============================================================================

# Enable topic monitoring (default: false)
MONITORING_ENABLED=false

# Cron schedule for monitoring (default: every 5 minutes)
MONITORING_SCHEDULE=*/5 * * * *

# Comma-separated list of channel names to monitor
MONITORING_CHANNELS=general,random

# Comma-separated list of topics to watch for
MONITORING_TOPICS=important,urgent,help

# Maximum messages to analyze per channel per run (default: 50)
MONITORING_MESSAGE_LIMIT=50

# Path for monitoring state persistence (default: ./monitor-state.json)
MONITORING_STATE_PATH=./monitor-state.json

# Process existing messages on first run (default: false)
MONITORING_PROCESS_EXISTING=false

# Number of messages to process on first run (default: 10)
MONITORING_FIRST_RUN_LIMIT=10

# =============================================================================
# Optional - LLM Configuration (for semantic topic analysis)
# =============================================================================

# Anthropic API key for Claude-based analysis
ANTHROPIC_API_KEY=

# Claude model to use (default: claude-sonnet-4-20250514)
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Maximum tokens for LLM response (default: 1000)
ANTHROPIC_MAX_TOKENS=1000
